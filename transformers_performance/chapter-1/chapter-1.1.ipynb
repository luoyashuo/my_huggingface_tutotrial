{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 æ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "seq_len, dataset_size = 512, 512\n",
    "dummy_data = {\n",
    "    \"input_ids\": np.random.randint(100, 30000, (dataset_size, seq_len)),\n",
    "    \"labels\": np.random.randint(0, 1, (dataset_size)),\n",
    "}\n",
    "ds = Dataset.from_dict(dummy_data)\n",
    "ds.set_format(\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 311 MB.\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹ç©ºé—² GPU å†…å­˜\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernels æ˜¯ç”¨äºæ‰§è¡Œåº•å±‚ GPU ä¸Šæ•°å­¦è¿ç®—çš„å‡½æ•°ï¼Œæˆ‘ä»¬è°ƒç”¨kernelå‡½æ•°å¯¹å­˜å‚¨åœ¨GPUå†…å­˜ä¸­çš„æ•°æ®è¿›è¡Œè®¡ç®—ã€‚æ¯ç§ç¥ç»ç½‘ç»œå±‚éƒ½éœ€è¦ä¸åŒçš„ kernels æ¥æ‰§è¡Œå…¶ç‰¹å®šçš„è®¡ç®—æ“ä½œï¼Œå¦‚å·ç§¯æ ¸å‡½æ•°ã€æ¿€æ´»å‡½æ•°ç­‰ï¼Œæ‰€ä»¥CUDAç¼–ç¨‹çš„æ ¸å¿ƒå…¶å®ä¹Ÿå°±æ˜¯å¦‚ä½•åˆç†çš„åˆ’åˆ†æ•°æ®å¹¶ä¸”é’ˆå¯¹æ•°æ®ç»“æ„ç¼–å†™é«˜æ•ˆçš„kernelå‡½æ•°ã€‚\n",
    "å½“ä¸€ä¸ªæ¨¡å‹åŠ è½½åˆ° GPU æ—¶ï¼Œä¸è¯¥æ¨¡å‹ç›¸å…³çš„è®¡ç®— kernels ä¹Ÿä¼šè¢«åŠ è½½åˆ° GPU ä¸Šï¼Œè¿™æ ·å¯ä»¥é¿å…æ¯æ¬¡æ‰§è¡Œè¿ç®—æ—¶éƒ½é‡å¤åŠ è½½ kernelsï¼Œæé«˜è¿ç®—æ•ˆç‡ã€‚ä½†éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒåŠ è½½ kernels ä¼šå ç”¨ GPU å­˜å‚¨ç©ºé—´ï¼Œé€šå¸¸å ç”¨å¤§çº¦1-2GBçš„å†…å­˜ã€‚å› æ­¤ï¼Œå³ä½¿åŠ è½½ä¸€ä¸ªå¾®å°çš„å¼ é‡åˆ° GPU ä¸Šï¼Œä¹Ÿä¼šè§¦å‘ kernels çš„åŠ è½½ï¼Œå¹¶ä¸”ä½ å¯ä»¥é€šè¿‡è§‚å¯Ÿ GPU æ˜¾å­˜çš„ä½¿ç”¨æ¥æŸ¥çœ‹ kernels å ç”¨çš„å†…å­˜å¤§å°ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 311 MB.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.ones((1, 1)).to(\"cuda\")\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 1599 MB.\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"/mnt/bn/lys-lq/HF_Caches/bert-large-uncased\" # è¿è¡Œåä¿®æ”¹\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path).to(\"cuda\")\n",
    "print_gpu_utilization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 10 14:20:49 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.129.06   Driver Version: 470.129.06   CUDA Version: 12.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:1A:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    73W / 300W |   1599MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    75W / 300W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œçœ‹çœ‹æ˜¾å­˜å˜åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/.local/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.143, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-10 14:20:54.952 n128-099-069:21338:21338 [0] NCCL INFO cudaDriverVersion 12020\n",
      "2024-10-10 14:20:54.953 n128-099-069:21338:21338 [0] NCCL INFO NCCL_SOCKET_FAMILY set by environment to AF_INET6\n",
      "2024-10-10 14:20:54.953 n128-099-069:21338:21338 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\n",
      "2024-10-10 14:20:54.953 n128-099-069:21338:21338 [0] NCCL INFO Bootstrap : Using eth0:fdbd:dc03:1:334::69<0>\n",
      "2024-10-10 14:20:54.954 n128-099-069:21338:21338 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation\n",
      "NCCL version 2.19.3-2+cuda12.2\n",
      "2024-10-10 14:20:55.334 n128-099-069:21338:24233 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.\n",
      "2024-10-10 14:20:55.364 n128-099-069:21338:24233 [1] NCCL INFO NCCL_SOCKET_FAMILY set by environment to AF_INET6\n",
      "2024-10-10 14:20:55.364 n128-099-069:21338:24233 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\n",
      "2024-10-10 14:20:55.365 n128-099-069:21338:24233 [1] NCCL INFO NCCL_IB_HCA set to mlx5_2:1\n",
      "2024-10-10 14:20:55.382 n128-099-069:21338:24233 [1] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [RO]; OOB eth0:fdbd:dc03:1:334::69<0>\n",
      "2024-10-10 14:20:55.383 n128-099-069:21338:24233 [1] NCCL INFO Using non-device net plugin version 0\n",
      "2024-10-10 14:20:55.383 n128-099-069:21338:24233 [1] NCCL INFO Using network IB\n",
      "2024-10-10 14:20:55.383 n128-099-069:21338:24232 [0] NCCL INFO Using non-device net plugin version 0\n",
      "2024-10-10 14:20:55.383 n128-099-069:21338:24232 [0] NCCL INFO Using network IB\n",
      "2024-10-10 14:20:55.384 n128-099-069:21338:24232 [0] NCCL INFO comm 0x133a0b60 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 1a000 commId 0xe54db08cd2d95676 - Init START\n",
      "2024-10-10 14:20:55.384 n128-099-069:21338:24233 [1] NCCL INFO comm 0x133a4660 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId 1b000 commId 0xe54db08cd2d95676 - Init START\n",
      "2024-10-10 14:20:55.399 n128-099-069:21338:24232 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\n",
      "2024-10-10 14:20:55.402 n128-099-069:21338:24233 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff\n",
      "2024-10-10 14:20:55.403 n128-099-069:21338:24233 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0\n",
      "2024-10-10 14:20:55.403 n128-099-069:21338:24232 [0] NCCL INFO Channel 00/02 :    0   1\n",
      "2024-10-10 14:20:55.403 n128-099-069:21338:24233 [1] NCCL INFO P2P Chunksize set to 524288\n",
      "2024-10-10 14:20:55.403 n128-099-069:21338:24232 [0] NCCL INFO Channel 01/02 :    0   1\n",
      "2024-10-10 14:20:55.403 n128-099-069:21338:24232 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1\n",
      "2024-10-10 14:20:55.403 n128-099-069:21338:24232 [0] NCCL INFO P2P Chunksize set to 524288\n",
      "2024-10-10 14:20:55.412 n128-099-069:21338:24233 [1] NCCL INFO Ring Channel 00/0 : 1[1] -> 0[0] via P2P/direct pointer\n",
      "2024-10-10 14:20:55.412 n128-099-069:21338:24232 [0] NCCL INFO Ring Channel 00/0 : 0[0] -> 1[1] via P2P/direct pointer\n",
      "2024-10-10 14:20:55.412 n128-099-069:21338:24233 [1] NCCL INFO Ring Channel 01/0 : 1[1] -> 0[0] via P2P/direct pointer\n",
      "2024-10-10 14:20:55.413 n128-099-069:21338:24232 [0] NCCL INFO Ring Channel 01/0 : 0[0] -> 1[1] via P2P/direct pointer\n",
      "2024-10-10 14:20:55.439 n128-099-069:21338:24232 [0] NCCL INFO Connected all rings\n",
      "2024-10-10 14:20:55.439 n128-099-069:21338:24232 [0] NCCL INFO Connected all trees\n",
      "2024-10-10 14:20:55.439 n128-099-069:21338:24233 [1] NCCL INFO Connected all rings\n",
      "2024-10-10 14:20:55.439 n128-099-069:21338:24233 [1] NCCL INFO Connected all trees\n",
      "2024-10-10 14:20:55.439 n128-099-069:21338:24233 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\n",
      "2024-10-10 14:20:55.439 n128-099-069:21338:24233 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\n",
      "2024-10-10 14:20:55.439 n128-099-069:21338:24232 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\n",
      "2024-10-10 14:20:55.439 n128-099-069:21338:24232 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\n",
      "2024-10-10 14:20:55.482 n128-099-069:21338:24233 [1] NCCL INFO comm 0x133a4660 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId 1b000 commId 0xe54db08cd2d95676 - Init COMPLETE\n",
      "2024-10-10 14:20:55.482 n128-099-069:21338:24232 [0] NCCL INFO comm 0x133a0b60 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 1a000 commId 0xe54db08cd2d95676 - Init COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 46.475, 'train_samples_per_second': 11.017, 'train_steps_per_second': 1.377, 'train_loss': 0.019991444423794746, 'epoch': 1.0}\n",
      "Time: 46.48\n",
      "Samples/second: 11.02\n",
      "GPU memory occupied: 11493 MB.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=4, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬çœ‹åˆ°,ä¸ä»…ä»…å°†æ¨¡å‹åŠ è½½åˆ°GPUç›¸æ¯”ï¼Œæ¨¡å‹è®­ç»ƒéœ€è¦ä½¿ç”¨æ›´å¤šçš„å†…å­˜ã€‚è¿™æ˜¯å› ä¸ºè®­ç»ƒè¿‡ç¨‹ä¸­æœ‰è®¸å¤šç»„ä»¶éƒ½ä½¿ç”¨äº†GPUå†…å­˜:\n",
    "\n",
    "æ¨¡å‹æƒé‡\n",
    "fp32ï¼šæ¯ä¸ªå‚æ•°4å­—èŠ‚\n",
    "æ··åˆç²¾åº¦è®­ç»ƒï¼šæ¯ä¸ªå‚æ•°6å­—èŠ‚(åŒæ—¶åœ¨å†…å­˜ä¸­ç»´æŠ¤fp32ç‰ˆæœ¬å’Œfp16ç‰ˆæœ¬)\n",
    "ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆoptimizer statesï¼‰\n",
    "normal AdamWï¼šæ¯ä¸ªå‚æ•°8å­—èŠ‚(ç»´æŠ¤ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡2ä¸ªçŠ¶æ€ï¼Œéƒ½æ˜¯fp32ç‰ˆæœ¬)\n",
    "8-bit AdamW(å¦‚bitsandbytes)ï¼šæ¯ä¸ªå‚æ•°2å­—èŠ‚ï¼ˆä¹Ÿæ˜¯ä¸¤ä¸ªçŠ¶æ€ï¼Œä½†éƒ½æ˜¯int8ç‰ˆæœ¬ï¼‰\n",
    "SGDï¼šæ¯ä¸ªå‚æ•°4å­—èŠ‚(ä»…ç»´æŠ¤1ä¸ªçŠ¶æ€)\n",
    "æ¢¯åº¦ï¼š æ¯ä¸ªå‚æ•°4å­—èŠ‚ï¼ˆæ— è®ºæ˜¯å¦å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼Œæ¢¯åº¦å§‹ç»ˆä»¥fp32å­˜å‚¨)\n",
    "Forward Activationsï¼šç”¨äºæ¢¯åº¦è®¡ç®—ï¼Œå…¶å¤§å°å–å†³äºè®¸å¤šå› ç´ ï¼Œæ¯”å¦‚åºåˆ—é•¿åº¦ã€éšå«å±‚å¤§å°å’Œæ‰¹é‡å¤§å°ã€‚\n",
    "ä¸´æ—¶ç¼“å­˜ï¼šå„ç§æš‚å­˜å˜é‡,ä¸€æ—¦è®¡ç®—å®Œæˆå°±ä¼šé‡Šæ”¾ï¼Œä½†å½“æ—¶å¯èƒ½éœ€è¦é¢å¤–å†…å­˜ï¼Œæ‰€ä»¥ä¹Ÿå¯èƒ½å¯¼è‡´OOMã€‚ç¼–ç¨‹æ—¶å¿…é¡»è€ƒè™‘è¿™äº›ä¸´æ—¶å˜é‡ï¼ŒåŠæ—¶é‡Šæ”¾ä¸å†éœ€è¦çš„å˜é‡ã€‚\n",
    "ç‰¹å®šåŠŸèƒ½çš„å†…å­˜ï¼šé™¤äº†ä»¥ä¸Šçš„æ¶ˆè€—ï¼Œå¯èƒ½è¿˜æœ‰ç‰¹æ®Šçš„å†…å­˜éœ€æ±‚ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨æŸæœç´¢ï¼ˆbeam searchï¼‰ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œéœ€è¦ç»´æŠ¤è¾“å…¥å’Œè¾“å‡ºçš„å¤šä¸ªå‰¯æœ¬ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/.local/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    **default_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'fp16'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/bn/lys-lq/my_huggingface_tutotrial/transformers_performance/chapter-1/chapter-1.1.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/lys-lq/my_huggingface_tutotrial/transformers_performance/chapter-1/chapter-1.1.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     model\u001b[39m.\u001b[39mgradient_checkpointing_enable()     \u001b[39m# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/lys-lq/my_huggingface_tutotrial/transformers_performance/chapter-1/chapter-1.1.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# åˆå§‹åŒ–Acceleratoræ—¶æŒ‡å®šå¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/lys-lq/my_huggingface_tutotrial/transformers_performance/chapter-1/chapter-1.1.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m accelerator \u001b[39m=\u001b[39m Accelerator(fp16\u001b[39m=\u001b[39;49mtraining_args\u001b[39m.\u001b[39;49mfp16)\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/lys-lq/my_huggingface_tutotrial/transformers_performance/chapter-1/chapter-1.1.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# å¯ç”¨adamw_bnb_8bit\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://icube%2Bicube/mnt/bn/lys-lq/my_huggingface_tutotrial/transformers_performance/chapter-1/chapter-1.1.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m model, optimizer, dataloader \u001b[39m=\u001b[39m accelerator\u001b[39m.\u001b[39mprepare(model, adam_bnb_optim, dataloader)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'fp16'"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "dataloader = DataLoader(ds, batch_size=training_args.per_device_train_batch_size)\n",
    "\n",
    "if training_args.gradient_checkpointing:\n",
    "    model.gradient_checkpointing_enable()     # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹\n",
    "\n",
    "# åˆå§‹åŒ–Acceleratoræ—¶æŒ‡å®šå¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "accelerator = Accelerator(fp16=training_args.fp16)\n",
    "# å¯ç”¨adamw_bnb_8bit\n",
    "model, optimizer, dataloader = accelerator.prepare(model, adam_bnb_optim, dataloader)\n",
    "\n",
    "model.train()\n",
    "for step, batch in enumerate(dataloader, start=1):\n",
    "    loss = model(**batch).loss\n",
    "    loss = loss / training_args.gradient_accumulation_steps\n",
    "    # è°ƒç”¨acceleratorè¿›è¡Œåå‘ä¼ æ’­\n",
    "    accelerator.backward(loss)\n",
    "    if step % training_args.gradient_accumulation_steps == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "fileId": "72c83960-b65d-42d9-8b77-49bd6231b312",
  "filePath": "/mnt/bn/lys-lq/my_huggingface_tutotrial/transformers_performance/chapter-1/chapter-1.1.ipynb",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
